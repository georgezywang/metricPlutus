{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from time import time\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlutusData(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform, dimension):\n",
    "        path = os.path.join(root_dir, csv_file)\n",
    "        dat = np.loadtxt(path, delimiter = \",\", dtype = np.float32, skiprows = 1)\n",
    "        self.inp = torch.from_numpy(dat[:, 3:11])\n",
    "        self.oup = torch.from_numpy(dat[:, dimension:2])\n",
    "        self.samples = dat.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inp[index], self.oup[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.samples\n",
    "\n",
    "#network Architecture\n",
    "class PlutusNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.b1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.b2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.b3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        ex = self.fc1(x)\n",
    "        ex = self.b1(ex)\n",
    "        ex = self.fc2(ex)\n",
    "        ex = self.b2(ex)\n",
    "        ex = self.fc3(ex)\n",
    "        ex = self.b3(ex)\n",
    "        ex = self.fc4(ex)\n",
    "\n",
    "        return ex\n",
    "\n",
    "#load and normalize data\n",
    "def constructTransform(mean, std):\n",
    "    mean = (mean,)\n",
    "    std = (std,)\n",
    "    normalization_transforms = [torchvision.transforms.ToTensor(), \n",
    "                                torchvision.transforms.Normalize(mean, std)]\n",
    "    transform = transforms.Compose(normalization_transforms)\n",
    "    return transform\n",
    "\n",
    "#train test split\n",
    "def splitData(dataset):\n",
    "    dataset_size = len(data_set)\n",
    "    indices = list(range(dataset_size))\n",
    "    dataset_size = len(data_set)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(test_split * dataset_size))\n",
    "    train_indices, test_indices = indices[split:], indices[:split]\n",
    "    return train_indices, test_indices\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "def train(model, x, y, optimizer, criterion):\n",
    "    model.zero_grad()\n",
    "    output = model(x)\n",
    "    loss =criterion(output,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = constructTransform(mean = 0, std = 1)\n",
    "#change the directory to your own when testing, ../content is colab specific\n",
    "data_set = PlutusData(\"data_new.csv\", \"../content\", transform = transform)\n",
    "batch_size = 4096\n",
    "test_split = 0.2\n",
    "train_indices, test_indices = splitData(PlutusData)\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "train_loader = torch.utils.data.DataLoader(data_set, batch_size = batch_size, sampler = train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(data_set, batch_size = batch_size, sampler = test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "features, labels = dataiter.next()\n",
    "print(\"features: \", features, \"Label: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plutusNet = PlutusNet(input_size = 8, hidden_size = 16)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "EPOCHS = 100\n",
    "optimizer = Adam(plutusNet.parameters(), lr = 0.0008)\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tracker = []\n",
    "for epoch in range(EPOCHS):\n",
    "  loss = 1\n",
    "  progress_bar = tqdm.notebook.tqdm(train_loader, ncols=1000)\n",
    "  for i, (features, labels) in enumerate(progress_bar):\n",
    "    x_train = Variable(features.view(-1, 8))\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = plutusNet(x_train)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_tracker.append(loss.data)                                  \n",
    "\n",
    "    if (i+1) % 100 == 0 or (i+1) == len(train_loader):   \n",
    "      progress_bar.set_description('Epoch [%d/%d], Step [%d/%d], Val, Training Loss: %.4f'\n",
    "              %(epoch+1, EPOCHS, i+1, len(train_loader), loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_tracker)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Step Number\")\n",
    "plt.title(\"Loss over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(loader, net):\n",
    "  for features, labels in loader:\n",
    "      features = Variable(features.view(-1, 8))\n",
    "      outputs = plutusNet(features)\n",
    "      print(outputs)\n",
    "  return outputs\n",
    "\n",
    "outTest = predict(test_loader, plutusNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = PlutusData(\"data_new.csv\", \"../content\", transform = transform, labelIndex = 1)\n",
    "loss_tracker = []\n",
    "for epoch in range(EPOCHS):\n",
    "  loss = 1\n",
    "  progress_bar = tqdm.notebook.tqdm(train_loader, ncols=1000)\n",
    "  for i, (features, labels) in enumerate(progress_bar):\n",
    "    x_train = Variable(features.view(-1, 8))\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = plutusNet(x_train)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_tracker.append(loss.data)                                  \n",
    "\n",
    "    if (i+1) % 100 == 0 or (i+1) == len(train_loader):   \n",
    "      progress_bar.set_description('Epoch [%d/%d], Step [%d/%d], Val, Training Loss: %.4f'\n",
    "              %(epoch+1, EPOCHS, i+1, len(train_loader), loss.data))\n",
    "outTest = predict(test_loader, plutusNet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
